{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TrainSelPy: Simplified Demonstration Examples\n",
    "\n",
    "This notebook provides simplified examples of the core features in TrainSelPy. It demonstrates key concepts without the complexity of the full comprehensive vignette, focusing on functionality that works reliably with the current implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T19:30:30.823769Z",
     "iopub.status.busy": "2025-03-14T19:30:30.823456Z",
     "iopub.status.idle": "2025-03-14T19:30:31.609293Z",
     "shell.execute_reply": "2025-03-14T19:30:31.608990Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31merror: externally-managed-environment\n",
      "\u001b[1;31m\n",
      "\u001b[1;31m× This environment is externally managed\n",
      "\u001b[1;31m╰─> To install Python packages system-wide, try brew install\n",
      "\u001b[1;31m    xyz, where xyz is the package you are trying to\n",
      "\u001b[1;31m    install.\n",
      "\u001b[1;31m    \n",
      "\u001b[1;31m    If you wish to install a Python library that isn't in Homebrew,\n",
      "\u001b[1;31m    use a virtual environment:\n",
      "\u001b[1;31m    \n",
      "\u001b[1;31m    python3 -m venv path/to/venv\n",
      "\u001b[1;31m    source path/to/venv/bin/activate\n",
      "\u001b[1;31m    python3 -m pip install xyz\n",
      "\u001b[1;31m    \n",
      "\u001b[1;31m    If you wish to install a Python application that isn't in Homebrew,\n",
      "\u001b[1;31m    it may be easiest to use 'pipx install xyz', which will manage a\n",
      "\u001b[1;31m    virtual environment for you. You can install pipx with\n",
      "\u001b[1;31m    \n",
      "\u001b[1;31m    brew install pipx\n",
      "\u001b[1;31m    \n",
      "\u001b[1;31m    You may restore the old behavior of pip by passing\n",
      "\u001b[1;31m    the '--break-system-packages' flag to pip, or by adding\n",
      "\u001b[1;31m    'break-system-packages = true' to your pip.conf file. The latter\n",
      "\u001b[1;31m    will permanently disable this error.\n",
      "\u001b[1;31m    \n",
      "\u001b[1;31m    If you disable this error, we STRONGLY recommend that you additionally\n",
      "\u001b[1;31m    pass the '--user' flag to pip, or set 'user = true' in your pip.conf\n",
      "\u001b[1;31m    file. Failure to do this can result in a broken Homebrew installation.\n",
      "\u001b[1;31m    \n",
      "\u001b[1;31m    Read more about this behavior here: <https://peps.python.org/pep-0668/>\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mnote: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\n",
      "\u001b[1;31mhint: See PEP 668 for the detailed specification. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Import necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import TrainSelPy components\n",
    "from trainselpy import (\n",
    "    make_data,\n",
    "    train_sel,\n",
    "    set_control_default,\n",
    "    dopt,\n",
    "    maximin_opt\n",
    ")\n",
    "\n",
    "# For visualization\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simple Subset Selection (Unordered)\n",
    "\n",
    "Let's start with a basic example of selecting an optimal subset using D-optimality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T19:30:31.611374Z",
     "iopub.status.busy": "2025-03-14T19:30:31.611106Z",
     "iopub.status.idle": "2025-03-14T19:30:31.707441Z",
     "shell.execute_reply": "2025-03-14T19:30:31.705535Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a small test dataset\n",
    "n_samples = 100\n",
    "n_features = 20\n",
    "\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "# Create a marker matrix (simulated genotypes)\n",
    "M = np.random.choice([-1, 0, 1], size=(n_samples, n_features), p=[0.25, 0.5, 0.25])\n",
    "\n",
    "# Create a relationship matrix (genomic relationships)\n",
    "K = np.dot(M, M.T) / n_features\n",
    "\n",
    "# Add a small value to the diagonal to ensure positive definiteness\n",
    "K += np.eye(n_samples) * 1e-6\n",
    "\n",
    "print(f\"Created dataset with {n_samples} samples and {n_features} features\")\n",
    "\n",
    "# Create the TrainSel data object\n",
    "ts_data = make_data(M=M)\n",
    "\n",
    "# For D-optimality, we need to add the feature matrix to the data\n",
    "ts_data[\"FeatureMat\"] = M\n",
    "\n",
    "# Set control parameters (limited iterations for example)\n",
    "control = set_control_default()\n",
    "control[\"niterations\"] = 30  # Reduced for demonstration\n",
    "control[\"npop\"] = 100\n",
    "\n",
    "# Run the selection algorithm with D-optimality\n",
    "result = train_sel(\n",
    "    data=ts_data,\n",
    "    candidates=[list(range(n_samples))],  # Select from all samples\n",
    "    setsizes=[10],                      # Select 10 samples\n",
    "    settypes=[\"UOS\"],                  # Unordered set\n",
    "    stat=dopt,                         # Use D-optimality\n",
    "    control=control,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\nSelected {len(result.selected_indices[0])} samples:\")\n",
    "print(f\"Selected indices: {result.selected_indices[0]}\")\n",
    "print(f\"Final fitness (D-optimality): {result.fitness:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T19:30:31.734321Z",
     "iopub.status.busy": "2025-03-14T19:30:31.733952Z",
     "iopub.status.idle": "2025-03-14T19:30:32.052462Z",
     "shell.execute_reply": "2025-03-14T19:30:32.052016Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Use PCA to reduce dimensions to 2D for visualization\n",
    "pca = PCA(n_components=2)\n",
    "M_reduced = pca.fit_transform(M)\n",
    "\n",
    "# Create a mask for selected samples\n",
    "selected_mask = np.zeros(n_samples, dtype=bool)\n",
    "selected_mask[result.selected_indices[0]] = True\n",
    "\n",
    "# Plot the samples in 2D space\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(M_reduced[~selected_mask, 0], M_reduced[~selected_mask, 1], alpha=0.5, label=\"Not Selected\")\n",
    "plt.scatter(M_reduced[selected_mask, 0], M_reduced[selected_mask, 1], color=\"red\", s=100, label=\"Selected\")\n",
    "plt.title(\"D-optimal Selection Visualization\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ordered Selection for TSP-like Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T19:30:32.054374Z",
     "iopub.status.busy": "2025-03-14T19:30:32.054203Z",
     "iopub.status.idle": "2025-03-14T19:30:34.246470Z",
     "shell.execute_reply": "2025-03-14T19:30:34.246168Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate a random distance matrix for a TSP-like problem\n",
    "n_cities = 30 # Reduced for faster execution\n",
    "np.random.seed(42)\n",
    "city_coords = np.random.rand(n_cities, 2) * 100  # Random coordinates in 2D space\n",
    "\n",
    "# Calculate distances between cities\n",
    "dist_matrix = np.zeros((n_cities, n_cities))\n",
    "for i in range(n_cities):\n",
    "    for j in range(n_cities):\n",
    "        dist_matrix[i, j] = np.sqrt(np.sum((city_coords[i] - city_coords[j])**2))\n",
    "\n",
    "# Convert to a form that TrainSelPy can use\n",
    "dist_df = pd.DataFrame(dist_matrix)\n",
    "\n",
    "# Create a data object for TrainSelPy\n",
    "ts_data = {\"DistMat\": dist_df}\n",
    "\n",
    "# Define a TSP fitness function (minimize total distance)\n",
    "def tsp_fitness(solution, data):\n",
    "    \"\"\"Calculate the negative total tour distance.\"\"\"\n",
    "    dist_mat = data[\"DistMat\"]\n",
    "    total_dist = 0\n",
    "    \n",
    "    # Calculate total tour distance including return to start\n",
    "    for i in range(len(solution)):\n",
    "        from_city = solution[i]\n",
    "        to_city = solution[(i + 1) % len(solution)]\n",
    "        total_dist += dist_mat.iloc[from_city, to_city]\n",
    "    \n",
    "    # Return negative distance (as TrainSelPy maximizes by default)\n",
    "    return -total_dist\n",
    "\n",
    "# Set control parameters\n",
    "control = set_control_default()\n",
    "control[\"niterations\"] = 100\n",
    "control[\"npop\"] = 1000\n",
    "control[\"mutprob\"] = 0.5\n",
    "control[\"crossprob\"] = 0.8\n",
    "\n",
    "# Run the TSP optimization\n",
    "start_time = time.time()\n",
    "result_tsp = train_sel(\n",
    "    data=ts_data,\n",
    "    candidates=[list(range(n_cities))],\n",
    "    setsizes=[n_cities],  # Select all cities (full tour)\n",
    "    settypes=[\"OS\"],      # Ordered set (the order matters)\n",
    "    stat=tsp_fitness,\n",
    "    control=control,\n",
    "    verbose=True\n",
    ")\n",
    "runtime = time.time() - start_time\n",
    "\n",
    "print(f\"\\nTSP optimization completed in {runtime:.2f} seconds\")\n",
    "print(f\"Tour length: {-result_tsp.fitness:.2f} units\")\n",
    "print(f\"Tour: {result_tsp.selected_indices[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T19:30:34.248099Z",
     "iopub.status.busy": "2025-03-14T19:30:34.248004Z",
     "iopub.status.idle": "2025-03-14T19:30:34.371257Z",
     "shell.execute_reply": "2025-03-14T19:30:34.370890Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the optimized tour\n",
    "tour = result_tsp.selected_indices[0]\n",
    "\n",
    "# Plot the tour\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.scatter(city_coords[:, 0], city_coords[:, 1], s=100, c='blue', alpha=0.7)\n",
    "\n",
    "# Add city labels\n",
    "for i in range(n_cities):\n",
    "    plt.text(city_coords[i, 0] + 0.5, city_coords[i, 1] + 0.5, str(i), fontsize=12)\n",
    "\n",
    "# Plot the tour path\n",
    "for i in range(len(tour)):\n",
    "    from_city = tour[i]\n",
    "    to_city = tour[(i + 1) % len(tour)]\n",
    "    plt.plot([city_coords[from_city, 0], city_coords[to_city, 0]],\n",
    "             [city_coords[from_city, 1], city_coords[to_city, 1]], 'r-', alpha=0.6)\n",
    "\n",
    "plt.title(f\"Optimized TSP Tour (Length: {-result_tsp.fitness:.2f})\")\n",
    "plt.xlabel(\"X Coordinate\")\n",
    "plt.ylabel(\"Y Coordinate\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mixed Integer Problem: Item Selection with Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T19:30:34.373039Z",
     "iopub.status.busy": "2025-03-14T19:30:34.372945Z",
     "iopub.status.idle": "2025-03-14T19:30:34.429504Z",
     "shell.execute_reply": "2025-03-14T19:30:34.429219Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a mixed integer problem\n",
    "# - Select 5 items from a set of 20\n",
    "# - Assign continuous weights (0-1) to each selected item\n",
    "# - Maximize a weighted sum function\n",
    "\n",
    "n_items = 20\n",
    "n_select = 5\n",
    "n_weights = n_select\n",
    "\n",
    "# Create random item values\n",
    "np.random.seed(123)\n",
    "item_values = np.random.rand(n_items) * 10\n",
    "item_costs = np.random.rand(n_items) * 5\n",
    "\n",
    "# Create data object\n",
    "mixed_data = {\n",
    "    \"values\": item_values,\n",
    "    \"costs\": item_costs,\n",
    "    \"budget\": 10.0  # Maximum total cost\n",
    "}\n",
    "\n",
    "# Define mixed integer fitness function\n",
    "def mixed_integer_fitness(int_solution, dbl_solution, data):\n",
    "    \"\"\"Fitness function for mixed integer problem.\"\"\"\n",
    "    selected_items = int_solution\n",
    "    weights = dbl_solution\n",
    "    \n",
    "    # Normalize weights to sum to 1\n",
    "    weights = np.array(weights) / np.sum(weights)\n",
    "    \n",
    "    # Calculate total value and cost\n",
    "    total_value = np.sum(data[\"values\"][selected_items] * weights)\n",
    "    total_cost = np.sum(data[\"costs\"][selected_items] * weights)\n",
    "    \n",
    "    # Apply penalty if over budget\n",
    "    if total_cost > data[\"budget\"]:\n",
    "        penalty = (total_cost - data[\"budget\"]) * 20\n",
    "        return total_value - penalty\n",
    "    \n",
    "    return total_value\n",
    "\n",
    "# Set control parameters\n",
    "control = set_control_default()\n",
    "control[\"niterations\"] = 30\n",
    "control[\"npop\"] = 100\n",
    "\n",
    "# Run the mixed integer optimization\n",
    "result_mixed = train_sel(\n",
    "    data=mixed_data,\n",
    "    candidates=[\n",
    "        list(range(n_items)),  # Integer candidates\n",
    "        list(range(n_weights))  # Just placeholder for continuous vars\n",
    "    ],\n",
    "    setsizes=[n_select, n_weights],\n",
    "    settypes=[\"UOS\", \"DBL\"],  # UOS for items, DBL for weights\n",
    "    stat=mixed_integer_fitness,\n",
    "    control=control,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Get results\n",
    "selected_items = result_mixed.selected_indices[0]\n",
    "selected_weights_raw = result_mixed.selected_values[0]\n",
    "selected_weights = np.array(selected_weights_raw) / np.sum(selected_weights_raw)\n",
    "\n",
    "# Calculate final metrics\n",
    "total_value = np.sum(item_values[selected_items] * selected_weights)\n",
    "total_cost = np.sum(item_costs[selected_items] * selected_weights)\n",
    "\n",
    "print(f\"\\nSelected items: {selected_items}\")\n",
    "print(f\"Normalized weights: {selected_weights}\")\n",
    "print(f\"Total value: {total_value:.2f}\")\n",
    "print(f\"Total cost: {total_cost:.2f} (Budget: {mixed_data['budget']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T19:30:34.431106Z",
     "iopub.status.busy": "2025-03-14T19:30:34.431016Z",
     "iopub.status.idle": "2025-03-14T19:30:34.564734Z",
     "shell.execute_reply": "2025-03-14T19:30:34.564413Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dataframe with all items\n",
    "all_items_df = pd.DataFrame({\n",
    "    'Item': range(n_items),\n",
    "    'Value': item_values,\n",
    "    'Cost': item_costs,\n",
    "    'Value/Cost': item_values / item_costs,\n",
    "    'Selected': ['Yes' if i in selected_items else 'No' for i in range(n_items)]\n",
    "})\n",
    "\n",
    "# Create a dataframe with just the selected items and their weights\n",
    "selected_df = pd.DataFrame({\n",
    "    'Item': selected_items,\n",
    "    'Value': item_values[selected_items],\n",
    "    'Cost': item_costs[selected_items],\n",
    "    'Weight': selected_weights,\n",
    "    'Weighted Value': item_values[selected_items] * selected_weights,\n",
    "    'Weighted Cost': item_costs[selected_items] * selected_weights\n",
    "})\n",
    "\n",
    "# Display the dataframes\n",
    "print(\"All Items:\")\n",
    "display(all_items_df)\n",
    "\n",
    "print(\"\\nSelected Items:\")\n",
    "display(selected_df)\n",
    "\n",
    "# Visualize the value-cost tradeoff\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(item_costs, item_values, s=80, alpha=0.6, label=\"Not Selected\")\n",
    "plt.scatter(item_costs[selected_items], item_values[selected_items], s=150, c='red', alpha=0.7, label=\"Selected\")\n",
    "\n",
    "# Add item labels\n",
    "for i in range(n_items):\n",
    "    plt.text(item_costs[i] + 0.1, item_values[i] + 0.1, str(i), fontsize=10)\n",
    "\n",
    "# Add weighted positions\n",
    "weighted_cost = np.sum(item_costs[selected_items] * selected_weights)\n",
    "weighted_value = np.sum(item_values[selected_items] * selected_weights)\n",
    "plt.scatter([weighted_cost], [weighted_value], s=200, c='green', marker='*', label=\"Weighted Result\")\n",
    "\n",
    "plt.axvline(x=mixed_data['budget'], color='black', linestyle='--', label=\"Budget Limit\")\n",
    "\n",
    "plt.title(\"Item Selection with Weights Optimization\")\n",
    "plt.xlabel(\"Cost\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Custom Optimization Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T19:30:34.566778Z",
     "iopub.status.busy": "2025-03-14T19:30:34.566634Z",
     "iopub.status.idle": "2025-03-14T19:30:42.627433Z",
     "shell.execute_reply": "2025-03-14T19:30:42.627094Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dataset for custom optimization\n",
    "n_samples = 100\n",
    "n_features = 30\n",
    "\n",
    "np.random.seed(42)\n",
    "# Create a marker matrix\n",
    "M_custom = np.random.choice([-1, 0, 1], size=(n_samples, n_features), p=[0.25, 0.5, 0.25])\n",
    "\n",
    "# Calculate distance matrix\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "dist_matrix = squareform(pdist(M_custom))\n",
    "\n",
    "# Create a TrainSel data object\n",
    "ts_data_custom = make_data(M=M_custom)\n",
    "ts_data_custom[\"FeatureMat\"] = M_custom\n",
    "ts_data_custom[\"DistMat\"] = pd.DataFrame(dist_matrix)\n",
    "\n",
    "# Define a custom optimization function combining D-optimality and maximin criteria\n",
    "def custom_composite_criterion(solution, data):\n",
    "    \"\"\"Custom criterion combining D-optimality and diversity.\"\"\"\n",
    "    # Calculate D-optimality\n",
    "    dopt_value = dopt(solution, data)\n",
    "    \n",
    "    # Calculate maximin criterion (diversity)\n",
    "    maximin_value = maximin_opt(solution, data)\n",
    "    \n",
    "    # Scale the objectives to make them comparable\n",
    "    # We're aiming to maximize both\n",
    "    scaled_dopt = dopt_value / 100  # Scale down D-optimality to match maximin range\n",
    "    \n",
    "    # Return weighted combination (can adjust weights to emphasize one objective more)\n",
    "    return 0.7 * scaled_dopt + 0.3 * maximin_value\n",
    "\n",
    "# Run the optimization with the custom criterion\n",
    "result_custom = train_sel(\n",
    "    data=ts_data_custom,\n",
    "    candidates=[list(range(n_samples))],\n",
    "    setsizes=[15],\n",
    "    settypes=[\"UOS\"],\n",
    "    stat=custom_composite_criterion,\n",
    "    control=set_control_default(),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Calculate individual criteria values for the solution\n",
    "selected = result_custom.selected_indices[0]\n",
    "dopt_val = dopt(selected, ts_data_custom)\n",
    "maximin_val = maximin_opt(selected, ts_data_custom)\n",
    "\n",
    "print(f\"\\nSelected {len(selected)} samples: {selected}\")\n",
    "print(f\"Composite fitness: {result_custom.fitness:.6f}\")\n",
    "print(f\"D-optimality: {dopt_val:.6f}\")\n",
    "print(f\"Maximin diversity: {maximin_val:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T19:30:42.629103Z",
     "iopub.status.busy": "2025-03-14T19:30:42.629005Z",
     "iopub.status.idle": "2025-03-14T19:30:47.523471Z",
     "shell.execute_reply": "2025-03-14T19:30:47.523128Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compare different criteria on the same dataset\n",
    "criteria = [\n",
    "    (\"D-optimality\", dopt),\n",
    "    (\"Maximin\", maximin_opt),\n",
    "    (\"Composite\", custom_composite_criterion)\n",
    "]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, criterion in criteria:\n",
    "    print(f\"\\nRunning optimization with {name} criterion...\")\n",
    "    \n",
    "    control = set_control_default()\n",
    "    control[\"niterations\"] = 30  # Reduced for demonstration\n",
    "    \n",
    "    result = train_sel(\n",
    "        data=ts_data_custom,\n",
    "        candidates=[list(range(n_samples))],\n",
    "        setsizes=[15],\n",
    "        settypes=[\"UOS\"],\n",
    "        stat=criterion,\n",
    "        control=control,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    selected = result.selected_indices[0]\n",
    "    results[name] = {\n",
    "        \"selected\": selected,\n",
    "        \"fitness\": result.fitness,\n",
    "        \"dopt\": dopt(selected, ts_data_custom),\n",
    "        \"maximin\": maximin_opt(selected, ts_data_custom)\n",
    "    }\n",
    "    \n",
    "    print(f\"  Fitness: {result.fitness:.6f}\")\n",
    "\n",
    "# Create a comparison table\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Criterion': [name for name, _ in criteria],\n",
    "    'D-optimality': [results[name]['dopt'] for name, _ in criteria],\n",
    "    'Maximin': [results[name]['maximin'] for name, _ in criteria]\n",
    "})\n",
    "\n",
    "print(\"\\nComparison of different criteria:\")\n",
    "display(comparison_df)\n",
    "\n",
    "# Visualize the results using PCA\n",
    "pca = PCA(n_components=2)\n",
    "M_reduced = pca.fit_transform(M_custom)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "for i, (name, _) in enumerate(criteria):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    \n",
    "    selected = results[name]['selected']\n",
    "    selected_mask = np.zeros(n_samples, dtype=bool)\n",
    "    selected_mask[selected] = True\n",
    "    \n",
    "    plt.scatter(M_reduced[~selected_mask, 0], M_reduced[~selected_mask, 1], alpha=0.5, label=\"Not Selected\")\n",
    "    plt.scatter(M_reduced[selected_mask, 0], M_reduced[selected_mask, 1], color=\"red\", s=100, label=\"Selected\")\n",
    "    \n",
    "    plt.title(f\"{name} Selection\")\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Balancing Genetic Gain and Diversity\n",
    "\n",
    "This example demonstrates how to balance genetic gain and diversity in a breeding context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T19:30:47.525376Z",
     "iopub.status.busy": "2025-03-14T19:30:47.525245Z",
     "iopub.status.idle": "2025-03-14T19:30:47.631593Z",
     "shell.execute_reply": "2025-03-14T19:30:47.631312Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a simulated breeding population dataset\n",
    "n_individuals = 100\n",
    "n_markers = 50\n",
    "\n",
    "np.random.seed(123)\n",
    "# Simulate marker data\n",
    "M = np.random.choice([-1, 0, 1], size=(n_individuals, n_markers), p=[0.25, 0.5, 0.25])\n",
    "\n",
    "# Create a relationship matrix (genomic relationships)\n",
    "K = np.dot(M, M.T) / n_markers\n",
    "\n",
    "# Add small diagonal value for numerical stability\n",
    "K += np.eye(n_individuals) * 1e-6\n",
    "\n",
    "# Simulate breeding values\n",
    "breeding_values = np.random.normal(0, 1, size=n_individuals)\n",
    "breeding_values = breeding_values * 10 + 100  # Scale for better visualization\n",
    "\n",
    "# Create data object\n",
    "breeding_data = {\n",
    "    \"breeding_values\": breeding_values,\n",
    "    \"K\": K\n",
    "}\n",
    "\n",
    "# Define a function that balances genetic gain and diversity\n",
    "def balanced_selection(solution, data):\n",
    "    \"\"\"Objective function balancing genetic gain and diversity.\"\"\"\n",
    "    breeding_values = data[\"breeding_values\"]\n",
    "    K = data[\"K\"]\n",
    "    \n",
    "    # Calculate genetic gain (mean breeding value of selected individuals)\n",
    "    genetic_gain = np.mean(breeding_values[solution])\n",
    "    \n",
    "    # Calculate inbreeding (mean relationship coefficient among selected)\n",
    "    selected_K = K[np.ix_(solution, solution)]\n",
    "    # Get off-diagonal elements (relationships between different individuals)\n",
    "    mask = ~np.eye(selected_K.shape[0], dtype=bool)\n",
    "    inbreeding = np.mean(selected_K[mask])\n",
    "    \n",
    "    # Balance the two objectives (maximize gain, minimize inbreeding)\n",
    "    # Scale genetic gain to be roughly in the same range as inbreeding\n",
    "    scaled_gain = (genetic_gain - 90) / 20  # Assuming breeding values around 100\n",
    "    \n",
    "    # Weighted combination\n",
    "    return 0.7 * scaled_gain - 0.3 * inbreeding\n",
    "\n",
    "# Set control parameters\n",
    "control = set_control_default()\n",
    "control[\"niterations\"] = 30\n",
    "control[\"npop\"] = 150\n",
    "\n",
    "# Run the optimization\n",
    "result_balanced = train_sel(\n",
    "    data=breeding_data,\n",
    "    candidates=[list(range(n_individuals))],\n",
    "    setsizes=[10],  # Select 10 individuals\n",
    "    settypes=[\"UOS\"],\n",
    "    stat=balanced_selection,\n",
    "    control=control,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Print the selected individuals\n",
    "selected = result_balanced.selected_indices[0]\n",
    "print(f\"\\nSelected individuals: {selected}\")\n",
    "print(f\"Fitness: {result_balanced.fitness:.4f}\")\n",
    "\n",
    "# Calculate the individual components\n",
    "genetic_gain = np.mean(breeding_values[selected])\n",
    "selected_K = K[np.ix_(selected, selected)]\n",
    "mask = ~np.eye(selected_K.shape[0], dtype=bool)\n",
    "inbreeding = np.mean(selected_K[mask])\n",
    "\n",
    "print(f\"Genetic gain: {genetic_gain:.4f}\")\n",
    "print(f\"Average inbreeding: {inbreeding:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T19:30:47.633203Z",
     "iopub.status.busy": "2025-03-14T19:30:47.633112Z",
     "iopub.status.idle": "2025-03-14T19:30:47.722634Z",
     "shell.execute_reply": "2025-03-14T19:30:47.722015Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compare with random selections\n",
    "n_random = 100\n",
    "random_gains = []\n",
    "random_inbreedings = []\n",
    "\n",
    "for _ in range(n_random):\n",
    "    random_selection = np.random.choice(n_individuals, size=10, replace=False)\n",
    "    \n",
    "    # Calculate gain\n",
    "    gain = np.mean(breeding_values[random_selection])\n",
    "    random_gains.append(gain)\n",
    "    \n",
    "    # Calculate inbreeding\n",
    "    sel_K = K[np.ix_(random_selection, random_selection)]\n",
    "    mask = ~np.eye(sel_K.shape[0], dtype=bool)\n",
    "    inb = np.mean(sel_K[mask])\n",
    "    random_inbreedings.append(inb)\n",
    "\n",
    "# Plot the comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(random_inbreedings, random_gains, alpha=0.5, label=\"Random Selections\")\n",
    "plt.scatter([inbreeding], [genetic_gain], color='red', s=100, label=\"Optimized Selection\")\n",
    "\n",
    "plt.title(\"Genetic Gain vs. Inbreeding\")\n",
    "plt.xlabel(\"Inbreeding (Average Relationship)\")\n",
    "plt.ylabel(\"Genetic Gain (Average Breeding Value)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Mixed Integer Optimization with Breeding Application\n",
    "\n",
    "This example shows how to optimize both individual selection and their contributions in a breeding program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T19:30:47.724415Z",
     "iopub.status.busy": "2025-03-14T19:30:47.724273Z",
     "iopub.status.idle": "2025-03-14T19:30:47.837701Z",
     "shell.execute_reply": "2025-03-14T19:30:47.837325Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a function for optimal contribution selection\n",
    "def optimal_contributions(int_sol, dbl_sol, data):\n",
    "    \"\"\"Calculate a combined objective for gain and inbreeding with contribution proportions.\"\"\"\n",
    "    # Normalize the contributions (proportions)\n",
    "    props = np.array(dbl_sol) / np.sum(dbl_sol)\n",
    "    \n",
    "    breeding_values = data[\"breeding_values\"]\n",
    "    K = data[\"K\"]\n",
    "    \n",
    "    # Weighted genetic gain\n",
    "    genetic_gain = np.sum(breeding_values[int_sol] * props)\n",
    "    \n",
    "    # Expected inbreeding (quadratic form: p'Kp)\n",
    "    selected_K = K[np.ix_(int_sol, int_sol)]\n",
    "    inbreeding = props.T @ selected_K @ props\n",
    "    \n",
    "    # Combine objectives (with appropriate scaling)\n",
    "    scaled_gain = (genetic_gain - 90) / 20\n",
    "    return 0.7 * scaled_gain - 0.3 * inbreeding\n",
    "\n",
    "# Optimize both selection and contributions\n",
    "result_ocs = train_sel(\n",
    "    data=breeding_data,\n",
    "    candidates=[\n",
    "        list(range(n_individuals)),  # Integer candidates\n",
    "        list(range(5))               # Just placeholder for 5 continuous variables\n",
    "    ],\n",
    "    setsizes=[5, 5],                 # Select 5 individuals with 5 contribution values\n",
    "    settypes=[\"UOS\", \"DBL\"],         # UOS for individuals, DBL for contributions\n",
    "    stat=optimal_contributions,\n",
    "    control=control,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Print results\n",
    "selected_inds = result_ocs.selected_indices[0]\n",
    "contribution_raw = result_ocs.selected_values[0]\n",
    "contributions = np.array(contribution_raw) / np.sum(contribution_raw)\n",
    "\n",
    "print(f\"\\nSelected individuals: {selected_inds}\")\n",
    "print(f\"Contributions: {contributions}\")\n",
    "\n",
    "# Calculate final metrics\n",
    "genetic_gain = np.sum(breeding_values[selected_inds] * contributions)\n",
    "selected_K = K[np.ix_(selected_inds, selected_inds)]\n",
    "inbreeding = contributions.T @ selected_K @ contributions\n",
    "\n",
    "print(f\"Genetic gain: {genetic_gain:.4f}\")\n",
    "print(f\"Expected inbreeding: {inbreeding:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This vignette has demonstrated the core features of TrainSelPy with reliable examples:\n",
    "\n",
    "1. **Unordered Subset Selection**: Optimal selection using D-optimality\n",
    "2. **Ordered Subset Selection**: Traveling salesman problem optimization\n",
    "3. **Mixed Integer Problems**: Item selection with weights optimization\n",
    "4. **Custom Optimization Criteria**: Creating custom objective functions\n",
    "5. **Breeding Applications**: Balancing genetic gain and diversity\n",
    "6. **Optimal Contribution Selection**: Mixed integer optimization for breeding\n",
    "\n",
    "These examples demonstrate TrainSelPy's capabilities for a wide range of optimization problems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
